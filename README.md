# Instructions

You can open the notebook file in either colab or jupyter to view the code used for training the agents. The document attatched with this project outlines a summary of every agent trained and how. 

## Summary 
Used an On-Policy Monte Carlo and Cross Entropy Method approach with Python to successfully
train agents in pre-built Gymnasium environments for discrete and continuous action spaces

Analyzed and investigated which epsilon, gamma, and alpha levels were the most efficient for training agents in different environments to optimize training times

Recursively built a maze environment with grids that had unique effects (teleport, ice, & trap) to train and test the agent in an adverse environment
